import numpy as np
import joblib
import librosa
from librosa import display
data, sampling_rate = librosa.load('Ravtess\\03-01-01-01-01-01-01.wav')
%pylab inline
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
librosa.display.waveplot(data, sr=sampling_rate)

import time
import os
path = 'Ravtess'
lst = []
start_time = time.time()
for subdir, dirs, files in os.walk(path):
    for file in files:
        try:
            X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')
            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) 
            file = int(file[7:8]) - 1 
            arr = mfccs, file
            lst.append(arr)
        except ValueError:
            continue
print("Time Taken to Load Data: %s seconds ---" % (time.time() - start_time))

X, y = zip(*lst)
X = np.asarray(X)
y = np.asarray(y)
X.shape, y.shape
X_name = 'X.joblib'
y_name = 'y.joblib'
save_dir = 'Ravtess_model'

savedX = joblib.dump(X, os.path.join(save_dir, X_name))
savedy = joblib.dump(y, os.path.join(save_dir, y_name))

import joblib
X = joblib.load('Ravtess_model\\X.joblib')
y = joblib.load('Ravtess_model\\y.joblib')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=42)
from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
predictions = dtree.predict(X_test)
from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,predictions))

# The Neural Network 
import numpy as np
x_traincnn = np.expand_dims(X_train, axis=2)

import keras
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding
from keras.utils import to_categorical
from keras.layers import Input, Flatten, Dropout, Activation
from keras.layers import Conv1D, MaxPooling1D
from keras.models import Model
from keras.callbacks import ModelCheckpoint

model = Sequential()

model.add(Conv1D(64, 5,padding='same',
                 input_shape=(40,1)))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(MaxPooling1D(pool_size=(4)))
model.add(Conv1D(128, 5,padding='same',))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(MaxPooling1D(pool_size=(4)))
model.add(Conv1D(256, 5,padding='same',))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(8))
model.add(Activation('softmax'))
opt = keras.optimizers.Adam(lr=0.00005,epsilon=1e-09,decay=0.0)

model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])

cnnhistory=model.fit(x_traincnn, y_train, batch_size=128, epochs=500, validation_data=(x_testcnn, y_test))

predictions = model.predict_classes(x_testcnn)
new_Ytest = y_test.astype(int)
from sklearn.metrics import classification_report
report = classification_report(new_Ytest, predictions)
from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(new_Ytest, predictions)
model.save('testing_model(ADAM).h5')
new_model=keras.models.load_model('testing_model(ADAM).h5')

loss, acc = new_model.evaluate(x_testcnn, y_test)
print("Accuracy: {:.2f}%".format(acc*100))
x_testcnn = np.expand_dims(X_test, axis=2)
